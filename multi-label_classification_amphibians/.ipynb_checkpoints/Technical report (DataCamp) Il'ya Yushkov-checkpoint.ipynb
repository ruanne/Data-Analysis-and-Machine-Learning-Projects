{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # for DataFrames and analysis\n",
    "import geopandas as gpd # for drawing maps\n",
    "import numpy as np # for calculations\n",
    "import seaborn as sns # # for plots\n",
    "import matplotlib.pyplot as plt # for plots\n",
    "from dataprep.eda import plot, plot_correlation, create_report, plot_missing # for EDA\n",
    "from sklearn.cluster import KMeans # for clusterization\n",
    "from scipy.cluster.hierarchy import dendrogram, ward # for clusterization\n",
    "from scipy.cluster.hierarchy import fcluster # for clusterization\n",
    "from sklearn.preprocessing import StandardScaler # for scaling\n",
    "from sklearn.metrics.cluster import silhouette_score # clusterization quality\n",
    "from sklearn.impute import KNNImputer # for missing values\n",
    "from sklearn.linear_model import Lasso # for regression\n",
    "from sklearn.ensemble import GradientBoostingRegressor # for predictions\n",
    "from sklearn.model_selection import train_test_split # split data\n",
    "from io import BytesIO # reading files\n",
    "from zipfile import ZipFile # unzip\n",
    "from urllib.request import urlopen # for downloading\n",
    "import eli5 # to show feature importance\n",
    "from scipy.stats import pearsonr # for Pearson correlation\n",
    "from scipy.stats import mannwhitneyu # Mann Whitney test\n",
    "plt.style.use('ggplot') # set matplotlib style\n",
    "pd.set_option('display.max_columns', None) # set max number of columns to show\n",
    "pd.set_option('display.max_rows', 30) # set max number of rows to show\n",
    "def norm(data):\n",
    "    return (data)/(max(data)-min(data)) # to norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create url variable, use it for building DataFrame, take a look \n",
    "url = 'https://raw.githubusercontent.com/datacamp/careerhub-data/master/Alcohol%20Consumption%20in%20Russia/alcohol-consumption-in-russia.csv'\n",
    "df = pd.read_csv(url)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the variable types in the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of rows for each region \n",
    "df.region.value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the columns\n",
    "df.isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the rows\n",
    "df[df.isna().sum(axis=1) > 0].region.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Crimea and Sevastopol rows\n",
    "# Fill the other missing values with zeros\n",
    "\n",
    "new_regions_mask = ((df.region == 'Sevastopol') | (df.region == 'Republic of Crimea'))\n",
    "df = df.drop(df[new_regions_mask].index, axis=0)\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data\n",
    "df_year = df.groupby('year')[['wine','beer','vodka','champagne','brandy']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use EDA\n",
    "plot_correlation(df_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use EDA\n",
    "create_report(df_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Common plot\n",
    "plt.figure(figsize=[10,6])\n",
    "plt.xticks(df_year.index)\n",
    "for col in df_year.columns:\n",
    "    sns.lineplot(data=df_year, x=df_year.index, y=norm(df_year[col]), label=str(col))\n",
    "plt.title('Alcohol consumption per year')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Alcohol consumption (normed)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for every drink\n",
    "fig, ax = plt.subplots(2, 3, figsize=(20,15))\n",
    "fig.delaxes(ax[1,2])\n",
    "\n",
    "ax[0,0].plot(df_year.index, df_year.wine, label='wine',color='r')\n",
    "ax[0,1].plot(df_year.index, df_year.beer, label='beer',color='b')\n",
    "ax[0,2].plot(df_year.index, df_year.champagne, label='champagne',color='g')\n",
    "ax[1,0].plot(df_year.index, df_year.vodka, label='vodka',color='m')\n",
    "ax[1,1].plot(df_year.index, df_year.brandy, label='brandy',color='y')\n",
    "\n",
    "ax[0,0].title.set_text('Wine consumption per year')\n",
    "ax[0,1].title.set_text('Beer consumption per year')\n",
    "ax[0,2].title.set_text('Champagne consumption per year')\n",
    "ax[1,0].title.set_text('Vodka consumption per year')\n",
    "ax[1,1].title.set_text('Brandy consumption per year')\n",
    "\n",
    "ax[0,0].set_xticks(df_year.index)\n",
    "ax[0,1].set_xticks(df_year.index)\n",
    "ax[0,2].set_xticks(df_year.index)\n",
    "ax[1,0].set_xticks(df_year.index)\n",
    "ax[1,1].set_xticks(df_year.index)\n",
    "\n",
    "ax[0,0].set_xticklabels(df_year.index, rotation=90)\n",
    "ax[0,1].set_xticklabels(df_year.index, rotation=90)\n",
    "ax[0,2].set_xticklabels(df_year.index, rotation=90)\n",
    "ax[1,0].set_xticklabels(df_year.index, rotation=90)\n",
    "ax[1,1].set_xticklabels(df_year.index, rotation=90)\n",
    "\n",
    "ax[0,0].set_ylabel('Litres per capita')\n",
    "ax[0,1].set_ylabel('Litres per capita')\n",
    "ax[0,2].set_ylabel('Litres per capita')\n",
    "ax[1,0].set_ylabel('Litres per capita')\n",
    "ax[1,1].set_ylabel('Litres per capita')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with light and strong alcohol, plot it\n",
    "df_year_weight = pd.DataFrame([df_year.wine + df_year.beer + df_year.champagne,\n",
    "                               df_year.vodka + df_year.brandy], index=['light','strong']).T\n",
    "plt.figure(figsize=[10,6])\n",
    "plt.xticks(df_year_weight.index)\n",
    "for col in df_year_weight.columns:\n",
    "    sns.lineplot(data=df_year_weight, x=df_year_weight.index, y=norm(df_year_weight[col]), label=str(col))\n",
    "plt.title('Alcohol consumption per year (light vs strong)')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Alcohol consumption (normed)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with all types of alcohol, plot it\n",
    "df_year_weight['All'] = df_year_weight.light + df_year_weight.strong\n",
    "plt.figure(figsize=[10,6])\n",
    "plt.xticks(df_year_weight.index)\n",
    "sns.lineplot(data=df_year_weight, x=df_year_weight.index, y=df_year_weight.All, label=\"The sum of all types of alcohol\")\n",
    "plt.title('Alcohol consumption per year (sum)')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Litres per capita')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create DataFrame with multiindex (region, year), plot it\n",
    "df_reg = df.set_index(['region','year']).sort_index()\n",
    "\n",
    "old_i = 'region'\n",
    "\n",
    "fig, ax = plt.subplots(2, 3, figsize=(20,15))\n",
    "fig.delaxes(ax[1,2])\n",
    "\n",
    "for i, row in df_reg.iterrows():\n",
    "\n",
    "    if i[0] != old_i:\n",
    "        df_temp = df_reg.loc[i[0]]\n",
    "\n",
    "\n",
    "        ax[0,0].plot(df_temp.index, df_temp.wine, label='wine',color='r', alpha=0.15)\n",
    "        ax[0,1].plot(df_temp.index, df_temp.beer, label='beer',color='b', alpha=0.15)\n",
    "        ax[0,2].plot(df_temp.index, df_temp.champagne, label='champagne',color='g', alpha=0.15)\n",
    "        ax[1,0].plot(df_temp.index, df_temp.vodka, label='vodka',color='m', alpha=0.15)\n",
    "        ax[1,1].plot(df_temp.index, df_temp.brandy, label='brandy',color='y', alpha=0.15)\n",
    "\n",
    "        old_i = i[0]\n",
    "\n",
    "ax[0,0].title.set_text('Wine consumption per year (all regions)')\n",
    "ax[0,1].title.set_text('Beer consumption per year (all regions)')\n",
    "ax[0,2].title.set_text('Champagne consumption per year (all regions)')\n",
    "ax[1,0].title.set_text('Vodka consumption per year (all regions)')\n",
    "ax[1,1].title.set_text('Brandy consumption per year (all regions)')\n",
    "\n",
    "ax[0,0].set_xticks(df_year.index)\n",
    "ax[0,1].set_xticks(df_year.index)\n",
    "ax[0,2].set_xticks(df_year.index)\n",
    "ax[1,0].set_xticks(df_year.index)\n",
    "ax[1,1].set_xticks(df_year.index)\n",
    "\n",
    "ax[0,0].set_xticklabels(df_year.index, rotation=90)\n",
    "ax[0,1].set_xticklabels(df_year.index, rotation=90)\n",
    "ax[0,2].set_xticklabels(df_year.index, rotation=90)\n",
    "ax[1,0].set_xticklabels(df_year.index, rotation=90)\n",
    "ax[1,1].set_xticklabels(df_year.index, rotation=90)\n",
    "\n",
    "ax[0,0].set_ylabel('Litres per capita')\n",
    "ax[0,1].set_ylabel('Litres per capita')\n",
    "ax[0,2].set_ylabel('Litres per capita')\n",
    "ax[1,0].set_ylabel('Litres per capita')\n",
    "ax[1,1].set_ylabel('Litres per capita')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of wine consumption using the main DataFrame\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.stripplot(data=df, x='year', y='wine')\n",
    "plt.title('Distribution of wine consumption')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Litres per capita')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot distribution of beer consumption using the main DataFrame\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.stripplot(data=df, x='year', y='beer')\n",
    "plt.title('Distribution of beer consumption')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Litres per capita')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot distribution of vodka consumption using the main DataFrame\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.stripplot(data=df, x='year', y='vodka')\n",
    "plt.title('Distribution of vodka consumption')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Litres per capita')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot distribution of champagne consumption using the main DataFrame\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.stripplot(data=df, x='year', y='champagne')\n",
    "plt.title('Distribution of champagne consumption')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Litres per capita')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot distribution of brandy consumption using the main DataFrame\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.stripplot(data=df, x='year', y='brandy')\n",
    "plt.title('Distribution of brandy consumption')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Litres per capita')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to build axes (x,y) for ECDF graph\n",
    "# Function takes an array and returns axes values\n",
    "def ecdf(data):\n",
    "    \n",
    "    n = len(data)\n",
    "    x = np.sort(data)\n",
    "    y = np.arange(1, n+1) / n\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create ECDF plot (comparison between 1998 and 2016)\n",
    "# Check null hypothesis: the first and the last year data are identically distributed\n",
    "# We can use permuted data to do that\n",
    "\n",
    "fig, ax = plt.subplots(2, 3, figsize=(20,15))\n",
    "fig.delaxes(ax[1,2])\n",
    "\n",
    "count = 0\n",
    "for col in df.columns[2:]:\n",
    "    first = np.array(df[df.year==1998][col])\n",
    "    last = np.array(df[df.year==2016][col])\n",
    "    x_first, y_first = ecdf(first)\n",
    "    x_last, y_last = ecdf(last)\n",
    "     \n",
    "    if count < 3:\n",
    "        i = 0\n",
    "        j = count\n",
    "    else:\n",
    "        i = 1\n",
    "        j = count - 3\n",
    "    ax[i,j].plot(x_first, y_first, color='r', marker='.', linestyle='none')\n",
    "    ax[i,j].plot(x_last, y_last, color='b', marker='.', linestyle='none')\n",
    "    \n",
    "    for perm_number in range(100):\n",
    "        check_data = np.concatenate((first,last))\n",
    "        permuted_data = np.random.permutation(check_data)\n",
    "\n",
    "        permuted_first = permuted_data[:len(first)]\n",
    "        permuted_last = permuted_data[len(first):]\n",
    "\n",
    "        x_permuted_first, y_permuted_first = ecdf(permuted_first)\n",
    "        x_permuted_last, y_permuted_last = ecdf(permuted_last)\n",
    "        \n",
    "        ax[i,j].plot(x_permuted_first, y_permuted_first, color='r', marker='.', linestyle='none', alpha=0.02)\n",
    "        ax[i,j].plot(x_permuted_last, y_permuted_last, color='b', marker='.', linestyle='none', alpha=0.02)\n",
    "    \n",
    "    ax[i,j].title.set_text(f'{(str(col)).capitalize()} ECDF distribution')\n",
    "    ax[i,j].set_xlabel('Litres per capita')\n",
    "    ax[i,j].set_ylabel('ECDF')\n",
    "    ax[i,j].legend(('1998', '2016'), loc='upper left')\n",
    "    ax[i,j].margins(0.02)\n",
    "    count += 1\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to generate mean of replicates\n",
    "\n",
    "def mean_of_permutation(data_1, data_2, size=10000):\n",
    "    \n",
    "    permuted_data_replicates = np.empty(size)\n",
    "    \n",
    "    for i in range(size):\n",
    "        concatenated_data = np.concatenate((data_1, data_2))\n",
    "        permuted_data = np.random.permutation(concatenated_data)\n",
    "\n",
    "        permuted_data_1 = permuted_data[:len(data_1)]\n",
    "        permuted_data_2 = permuted_data[len(data_1):]\n",
    "\n",
    "        permuted_data_replicates[i] = np.mean(permuted_data_1) - np.mean(permuted_data_2)\n",
    "\n",
    "    return permuted_data_replicates\n",
    "\n",
    "# Check null hypothesis: the first and the last year data of 'champagne' and 'brandy' are identically distributed\n",
    "\n",
    "for col in ['champagne', 'brandy']:\n",
    "    \n",
    "    real_diff_means = np.mean(df[df.year==2016][col]) - np.mean(df[df.year==1998][col])\n",
    "    permuted_replicates = mean_of_permutation(df[df.year==2016][col],df[df.year==1998][col], 100000)\n",
    "    p = np.sum(permuted_replicates >= real_diff_means) / len(permuted_replicates)\n",
    "\n",
    "\n",
    "    print(f'Manual p-val of {col} = {p}')\n",
    "    print(f'Scipy p-val of {col} = {pearsonr(df[df.year==2016][col],df[df.year==1998][col])[1]}')\n",
    "    print(f'Mann Whitney p-val of {col} = {mannwhitneyu(df[df.year==2016][col],df[df.year==1998][col])[1]}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check null hypothesis: the basic dataset variables are completely uncorrelated\n",
    "\n",
    "for i in range(2,6):\n",
    "    for j in range(i+1,7):\n",
    "        r_obs = pearsonr(df[df.columns[i]], df[df.columns[j]])\n",
    "        perm_replicates = np.empty(10000)\n",
    "        for repl_num in range(10000):\n",
    "            first_permuted = np.random.permutation(df[df.columns[i]])\n",
    "            perm_replicates[repl_num] = abs(pearsonr(first_permuted, df[df.columns[j]])[0])\n",
    "\n",
    "        p = np.sum(perm_replicates >= abs(r_obs[0]))/10000\n",
    "        \n",
    "        if (p > 0.05) or (r_obs[1] > 0.05):\n",
    "\n",
    "            print(f'manual p-val {df.columns[i]} and {df.columns[j]} = {p}')\n",
    "            print(f'scipy p-val {df.columns[i]} and {df.columns[j]} = {r_obs[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create wide DataFrame by pivot_table\n",
    "df_clus = df_reg.reset_index(1)\n",
    "df_clus = pd.pivot_table(df_clus, values=['wine','beer','vodka','champagne','brandy'], index=df_clus.index,\n",
    "                    columns='year')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization and KMeans loop \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df_clus)\n",
    "X_scaled = scaler.transform(df_clus)\n",
    "for i in range(2,10):\n",
    "    kmeans = KMeans(i)\n",
    "    kmeans.fit(X_scaled)\n",
    "    print(silhouette_score(X_scaled, kmeans.labels_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results of clusterization \n",
    "kmeans = KMeans(3)\n",
    "kmeans.fit(X_scaled)\n",
    "for reg, ind in sorted(zip(df_clus.index, kmeans.labels_), key=lambda x: x[1], reverse=False):\n",
    "    print(reg, ind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download map of Russia and create Geopandas DataFrame\n",
    "resp = urlopen(\"https://biogeo.ucdavis.edu/data/gadm3.6/gpkg/gadm36_RUS_gpkg.zip\")\n",
    "zipfile = ZipFile(BytesIO(resp.read()))\n",
    "zipfile.namelist()[0]\n",
    "with zipfile.open(zipfile.namelist()[0]) as myfile:\n",
    "    drw_russia = gpd.read_file(myfile)\n",
    "\n",
    "# Create Pandas Dataframe with region names and cluster labels\n",
    "df_cluster_three = pd.DataFrame(list(sorted(zip(df_clus.index, kmeans.labels_), key=lambda x: x[1], \n",
    "             reverse=False)),  columns=['region','cluster'])\n",
    "\n",
    "# Unification of region names (‘'NAME_1’ column in Geopandas Dataframe)\n",
    "drw_russia = drw_russia.replace({'NAME_1': {'Adygey':'Republic of Adygea', 'Altay':'Altai Krai', 'Amur':'Amur Oblast',\n",
    "                               \"Arkhangel'sk\":'Arkhangelsk Oblast', \"Astrakhan'\":'Astrakhan Oblast',\n",
    "                               'Bashkortostan':'Republic of Bashkortostan', 'Belgorod': 'Belgorod Oblast',\n",
    "                               'Bryansk':'Bryansk Oblast', 'Buryat':'Republic of Buryatia',\n",
    "                               'Chechnya':'Chechen Republic', 'Chelyabinsk':'Chelyabinsk Oblast',\n",
    "                               'Chukot':'Chukotka Autonomous Okrug', 'Chuvash':'Chuvash Republic',\n",
    "                               'City of St. Petersburg':'Saint Petersburg','Dagestan':'Republic of Dagestan',\n",
    "                               'Gorno-Altay':'Altai Republic', 'Ingush':'Republic of Ingushetia',\n",
    "                               'Irkutsk':'Irkutsk Oblast', 'Ivanovo':'Ivanovo Oblast',\n",
    "                               'Kabardin-Balkar':'Kabardino-Balkar Republic', 'Kaliningrad':'Kaliningrad Oblast',\n",
    "                               'Kalmyk':'Republic of Kalmykia', 'Kaluga':'Kaluga Oblast',\n",
    "                               'Kamchatka':'Kamchatka Krai','Karachay-Cherkess':'Karachay-Cherkess Republic',\n",
    "                               'Karelia':'Republic of Karelia', 'Kemerovo':'Kemerovo Oblast',\n",
    "                               'Khabarovsk':'Khabarovsk Krai', 'Khakass':'Republic of Khakassia',\n",
    "                               'Khanty-Mansiy':'Khanty–Mansi Autonomous Okrug – Yugra', 'Kirov':'Kirov Oblast',\n",
    "                               'Komi':'Komi Republic', 'Kostroma':'Kostroma Oblast','Krasnodar':'Krasnodar Krai',\n",
    "                               'Krasnoyarsk':'Krasnoyarsk Krai', 'Kurgan':'Kurgan Oblast', 'Kursk':'Kursk Oblast',\n",
    "                               'Leningrad':'Leningrad Oblast', 'Lipetsk':'Lipetsk Oblast','Maga Buryatdan':'Magadan Oblast',\n",
    "                               'Mariy-El':'Mari El Republic', 'Mordovia':'Republic of Mordovia', 'Moscow City':'Moscow',\n",
    "                               'Moskva':'Moscow Oblast', 'Murmansk':'Murmansk Oblast', 'Nenets':'Nenets Autonomous Okrug',\n",
    "                               'Nizhegorod':'Nizhny Novgorod Oblast', 'North Ossetia':'Republic of North Ossetia-Alania',\n",
    "                               'Novgorod':'Novgorod Oblast', 'Novosibirsk':'Novosibirsk Oblast', 'Omsk':'Omsk Oblast',\n",
    "                               'Orel': 'Oryol Oblast', 'Orenburg':'Orenburg Oblast', 'Penza':'Penza Oblast',\n",
    "                               \"Perm'\":'Perm Krai', \"Primor'ye\":'Primorsky Krai', 'Pskov':'Pskov Oblast',\n",
    "                               'Rostov':'Rostov Oblast', \"Ryazan'\":'Ryazan Oblast', 'Sakha':'Sakha (Yakutia) Republic',\n",
    "                               'Sakhalin':'Sakhalin Oblast', 'Samara':'Samara Oblast', 'Saratov':'Saratov Oblast',\n",
    "                               'Smolensk':'Smolensk Oblast', \"Stavropol'\":'Stavropol Krai', 'Sverdlovsk':'Sverdlovsk Oblast',\n",
    "                               'Tambov':'Tambov Oblast', 'Tatarstan':'Republic of Tatarstan', 'Tomsk':'Tomsk Oblast',\n",
    "                               'Tula':'Tula Oblast', 'Tuva':'Tuva Republic', \"Tver'\":'Tver Oblast',\n",
    "                               \"Tyumen'\":'Tyumen Oblast', 'Udmurt':'Udmurt Republic', \"Ul'yanovsk\":'Ulyanovsk Oblast',\n",
    "                               'Vladimir':'Vladimir Oblast', 'Volgograd':'Volgograd Oblast', 'Vologda':'Vologda Oblast',\n",
    "                               'Voronezh':'Voronezh Oblast', 'Yamal-Nenets':'Yamalo-Nenets Autonomous Okrug',\n",
    "                               \"Yaroslavl'\":'Yaroslavl Oblast','Yevrey':'Jewish Autonomous Oblast',\n",
    "                               \"Zabaykal'ye\":'Zabaykalsky Krai'}})\n",
    "\n",
    "\n",
    "# Merge Pandas and Geopandas DataFrames\n",
    "drw_russia_clus = drw_russia.merge(df_cluster_three, how='left', left_on='NAME_1', right_on='region')\n",
    "\n",
    "# Draw map\n",
    "drw_russia_clus.plot('cluster', figsize=(10, 6), legend=True, categorical=True, cmap='plasma')\n",
    "plt.xlim(0,200)\n",
    "plt.title('Results of KMeans clusterization')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clusterization and building dendrogram\n",
    "linkage_array = ward(X_scaled)\n",
    "plt.figure(figsize=(20,15))\n",
    "dendrogram(linkage_array, labels=df_clus.index, leaf_rotation=90,leaf_font_size=12)\n",
    "plt.tight_layout\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the regions into three clusters, add this information to Geopandas DataFrame\n",
    "labels = fcluster(linkage_array, 3, criterion='maxclust')\n",
    "drw_russia_clus['cluster_dendro'] = 0\n",
    "for reg, ind in sorted(zip(df_clus.index, labels), key=lambda x: x[1], reverse=False):\n",
    "    drw_russia_clus.loc[drw_russia_clus.NAME_1 == reg, 'cluster_dendro'] = ind\n",
    "\n",
    "# Draw map\n",
    "drw_russia_clus.plot('cluster_dendro', figsize=(10, 6), legend=True, categorical=True, cmap='magma')\n",
    "plt.xlim(0,200)\n",
    "plt.title('Results of agglomerative clustering')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge main DataFrame and DataFrame with cluster labels, and then group by ‘cluster’ using 'mean'\n",
    "df_clus_three = df.merge(df_cluster_three, how='left', on='region')\n",
    "df_clus_three.groupby(['cluster']).mean().drop('year', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by ‘cluster’ using 'median'\n",
    "df_clus_three.groupby(['cluster']).median().drop('year', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data by clusters, draw plots\n",
    "df_clus_three_grouped = df_clus_three.groupby(['cluster', 'year']).mean()\n",
    "\n",
    "fig, ax = plt.subplots(3, 5, figsize=(20,15))\n",
    "\n",
    "for i in range(3):\n",
    "\n",
    "    ax[i,0].plot(df_clus_three_grouped.loc[i].index, df_clus_three_grouped.loc[i].wine, label=f'cluster {i}: wine',color='r')\n",
    "    ax[i,1].plot(df_clus_three_grouped.loc[i].index, df_clus_three_grouped.loc[i].beer, label=f'cluster {i}: beer',color='b')\n",
    "    ax[i,2].plot(df_clus_three_grouped.loc[i].index, df_clus_three_grouped.loc[i].champagne, label=f'cluster {i}: champagne',color='g')\n",
    "    ax[i,3].plot(df_clus_three_grouped.loc[i].index, df_clus_three_grouped.loc[i].vodka, label=f'cluster {i}: vodka',color='m')\n",
    "    ax[i,4].plot(df_clus_three_grouped.loc[i].index, df_clus_three_grouped.loc[i].brandy, label=f'cluster {i}: brandy',color='y')\n",
    "\n",
    "    ax[i,0].title.set_text(f'Wine per year, cluster {i}')\n",
    "    ax[i,1].title.set_text(f'Beer per year, cluster {i}')\n",
    "    ax[i,2].title.set_text(f'Champagne per year, cluster {i}')\n",
    "    ax[i,3].title.set_text(f'Vodka per year, cluster {i}')\n",
    "    ax[i,4].title.set_text(f'Brandy per year, cluster {i}')\n",
    "\n",
    "    ax[i,0].set_xticks(df_clus_three_grouped.loc[0].index)\n",
    "    ax[i,1].set_xticks(df_clus_three_grouped.loc[0].index)\n",
    "    ax[i,2].set_xticks(df_clus_three_grouped.loc[0].index)\n",
    "    ax[i,3].set_xticks(df_clus_three_grouped.loc[0].index)\n",
    "    ax[i,4].set_xticks(df_clus_three_grouped.loc[0].index)\n",
    "\n",
    "    ax[i,0].set_xticklabels(df_clus_three_grouped.loc[0].index, rotation=90)\n",
    "    ax[i,1].set_xticklabels(df_clus_three_grouped.loc[0].index, rotation=90)\n",
    "    ax[i,2].set_xticklabels(df_clus_three_grouped.loc[0].index, rotation=90)\n",
    "    ax[i,3].set_xticklabels(df_clus_three_grouped.loc[0].index, rotation=90)\n",
    "    ax[i,4].set_xticklabels(df_clus_three_grouped.loc[0].index, rotation=90)\n",
    "\n",
    "    ax[i,0].set_ylabel('Litres per capita')\n",
    "    ax[i,1].set_ylabel('Litres per capita')\n",
    "    ax[i,2].set_ylabel('Litres per capita')\n",
    "    ax[i,3].set_ylabel('Litres per capita')\n",
    "    ax[i,4].set_ylabel('Litres per capita')\n",
    "\n",
    "plt.tight_layout()\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show small cluster regions\n",
    "smallest_cluster = np.argmin(df_clus_three.groupby(['cluster'])['year'].count())\n",
    "pd.DataFrame(df_clus_three[df_clus_three.cluster == smallest_cluster].region.unique(), columns=['region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variable and add it to DataFrame\n",
    "muslim_regions = ['Republic of Ingushetia', 'Chechen Republic', 'Republic of Dagestan',\n",
    "'Kabardino-Balkar Republic', 'Karachay-Cherkess Republic', 'Republic of Bashkortostan',\n",
    "'Republic of Tatarstan']\n",
    "df_clus_three['muslim'] = 0\n",
    "muslim_mask = df_clus_three[df_clus_three.region.isin(muslim_regions)].index\n",
    "df_clus_three.loc[muslim_mask, 'muslim'] = 1\n",
    "\n",
    "# Check intersection between muslim dummy variable and clusters\n",
    "pd.crosstab(df_clus_three.groupby('region').mean().cluster, df_clus_three.groupby('region').mean().muslim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and cleaning data\n",
    "# Create link\n",
    "grp_link = 'https://eng.rosstat.gov.ru/storage/mediabank/CEIrYOo9/per_capita_dusha98-19_eng.xlsx'\n",
    "\n",
    "# Skip and drop empty rows\n",
    "df_grp = pd.read_excel(grp_link, skiprows=5, index_col=0)\n",
    "df_grp = df_grp.dropna(axis=0)\n",
    "\n",
    "# Drop row with summary information\n",
    "df_grp = df_grp.drop(index=df_grp.index[0], axis=0)\n",
    "\n",
    "# Drop rows with summary information (by district)\n",
    "df_grp = df_grp.drop(index=df_grp[df_grp.index.str.contains('District')].index, axis=0)\n",
    "\n",
    "# NaN look like ‘…' in original DataFrame, we need to replace them\n",
    "df_grp = df_grp.replace({'…' : np.nan})\n",
    "\n",
    "# Change column names (str instead of int)\n",
    "df_grp.columns = list(map(str, df_grp.columns))\n",
    "\n",
    "df_grp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at missing data\n",
    "df_grp.index\n",
    "df_grp.loc['Republic of Komi':'Kaliningrad region']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing data\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "df_grp_filled = imputer.fit_transform(df_grp)\n",
    "\n",
    "# Create DataFrame and put the regions to the column\n",
    "df_grp_filled = pd.DataFrame(df_grp_filled, columns=df_grp.columns, index=df_grp.index)\n",
    "df_grp_filled = df_grp_filled.reset_index().rename(columns={'index':'region'})\n",
    "\n",
    "# Unification of region names\n",
    "df_grp_filled.region = df_grp_filled.region.str.replace('region', 'Oblast')\n",
    "df_grp_filled = df_grp_filled.drop(index=df_grp_filled[(df_grp_filled.region == 'Arkhangelsk Oblast')\n",
    "                      | (df_grp_filled.region == 'Tyumen Oblast')].index, axis=0)\n",
    "df_grp_filled = df_grp_filled.replace({'region': {'Altai territory':'Altai Krai',\n",
    "                               '     Arkhangelsk Oblast without Nenets autonomous area':'Arkhangelsk Oblast',\n",
    "                               'Republic of Bashkortastan':'Republic of Bashkortostan',\n",
    "                               'Chukotka autonomous area':'Chukotka Autonomous Okrug',\n",
    "                               'The City of Saint-Petersburg':'Saint Petersburg',\n",
    "                               'Republic of Altai':'Altai Republic', \n",
    "                               'Kabardian-Balkar Republic':'Kabardino-Balkar Republic',\n",
    "                               'Kamchatka territory':'Kamchatka Krai',\n",
    "                               'Karachaev-Circassian Republic':'Karachay-Cherkess Republic',\n",
    "                               'Khabarovsk territory':'Khabarovsk Krai',\n",
    "                               '           of which Khanty-Mansi autonomous\\narea - Yugra':'Khanty–Mansi Autonomous Okrug – Yugra',\n",
    "                               'Republic of Komi':'Komi Republic', 'Krasnodar territory':'Krasnodar Krai',\n",
    "                               'Krasnoyarsk territory':'Krasnoyarsk Krai', 'Republic of Mariy El':'Mari El Republic',\n",
    "                               'The City of Moscow':'Moscow',\n",
    "                               '     of which Nenets autonomous area':'Nenets Autonomous Okrug',\n",
    "                               'Nizhny novgorod Oblast':'Nizhny Novgorod Oblast', \n",
    "                               'Republic of North Ossetia–Alania':'Republic of North Ossetia-Alania',\n",
    "                               'Perm territory':'Perm Krai', 'Primorsky territory':'Primorsky Krai',\n",
    "                               'Republic of Sakha (Yakutia)':'Sakha (Yakutia) Republic',\n",
    "                               'Stavropol territory':'Stavropol Krai', 'Republic of Tyva':'Tuva Republic',\n",
    "                               '           Tyumen Oblast (without Khanty-Mansi autonomous area - Yugra and Yamalo-Nenets autonomous area)':'Tyumen Oblast',\n",
    "                               '           Yamalo-Nenets autonomous\\narea':'Yamalo-Nenets Autonomous Okrug',\n",
    "                               'Jewish autonomous Oblast':'Jewish Autonomous Oblast',\n",
    "                               'Zabaykalsky territory':'Zabaykalsky Krai'}})\n",
    "\n",
    "# Check that everything is fine\n",
    "set(df_grp_filled.region).intersection(set(df_clus_three.region))\n",
    "set(df_grp_filled.region).difference(set(df_clus_three.region))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify DataFrame to long format\n",
    "df_grp_filled.columns = 'A' + df_grp_filled.columns\n",
    "df_grp_filled = df_grp_filled.rename(columns={'Aregion':'region'})\n",
    "df_grp_long = pd.wide_to_long(df_grp_filled, [\"A\"], i=\"region\", j=\"year\")\n",
    "df_grp_long = df_grp_long.reset_index()\n",
    "df_grp_long = df_grp_long.drop(index=df_grp_long[(df_grp_long.year == 2017)\n",
    "                      | (df_grp_long.year == 2018) | (df_grp_long.year == 2019)].index, axis=0)\n",
    "df_grp_long = df_grp_long.rename(columns={'A':'GRP'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shapes\n",
    "print(df_grp_long.shape)\n",
    "print(df_clus_three.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "df_with_grp = df_clus_three.merge(df_grp_long, how='left', on=['region','year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot correlation\n",
    "plot_correlation(df_with_grp.drop(['year','cluster','muslim'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_report(df_with_grp.drop(['year','cluster','muslim'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "salary_link = 'https://rosstat.gov.ru/storage/mediabank/mVYy3Iwl/t4.xlsx'\n",
    "df_salary = pd.read_excel(salary_link, skiprows=3, index_col=0)\n",
    "\n",
    "# Drop empty rows with precautions: in some rows creators of dataset used NaN for unknown values\n",
    "# instead of traditional “...”. So we drop rows only with high value of NaNs\n",
    "df_salary = df_salary.drop(index=df_salary[df_salary.isna().sum(axis=1) > 10].index, axis=0)\n",
    "\n",
    "# Check the indexes (you can use Google translate to be sure)\n",
    "df_grp_temp = pd.read_excel(grp_link, skiprows=5, index_col=0)\n",
    "df_grp_temp = df_grp_temp.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_salary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grp_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_salary.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grp_temp.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set English index\n",
    "df_salary.index = df_grp_temp.index\n",
    "\n",
    "# Clean data and fill NaN using the same methods\n",
    "df_salary = df_salary.drop(index=df_salary.index[0], axis=0)\n",
    "df_salary = df_salary.drop(index=df_salary[df_salary.index.str.contains('District')].index, axis=0)\n",
    "df_salary.columns = list(map(str, df_salary.columns))\n",
    "df_salary = df_salary.replace({'…' : np.nan})\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "df_salary_filled = imputer.fit_transform(df_salary)\n",
    "df_salary_filled = pd.DataFrame(df_salary_filled, columns=df_salary.columns, index=df_salary.index)\n",
    "df_salary_filled = df_salary_filled.reset_index().rename(columns={'index':'region'})\n",
    "\n",
    "df_salary_filled.region = df_salary_filled.region.str.replace('region', 'Oblast')\n",
    "\n",
    "df_salary_filled = df_salary_filled.drop(index=df_salary_filled[(df_salary_filled.region == 'Arkhangelsk Oblast')\n",
    "                      | (df_salary_filled.region == 'Tyumen Oblast')].index, axis=0)\n",
    "\n",
    "df_salary_filled = df_salary_filled.replace({'region': {'Altai territory':'Altai Krai',\n",
    "                               '     Arkhangelsk Oblast without Nenets autonomous area':'Arkhangelsk Oblast',\n",
    "                               'Republic of Bashkortastan':'Republic of Bashkortostan',\n",
    "                               'Chukotka autonomous area':'Chukotka Autonomous Okrug',\n",
    "                               'The City of Saint-Petersburg':'Saint Petersburg',\n",
    "                               'Republic of Altai':'Altai Republic', \n",
    "                               'Kabardian-Balkar Republic':'Kabardino-Balkar Republic',\n",
    "                               'Kamchatka territory':'Kamchatka Krai',\n",
    "                               'Karachaev-Circassian Republic':'Karachay-Cherkess Republic',\n",
    "                               'Khabarovsk territory':'Khabarovsk Krai',\n",
    "                               '           of which Khanty-Mansi autonomous\\narea - Yugra':'Khanty–Mansi Autonomous Okrug – Yugra',\n",
    "                               'Republic of Komi':'Komi Republic', 'Krasnodar territory':'Krasnodar Krai',\n",
    "                               'Krasnoyarsk territory':'Krasnoyarsk Krai', 'Republic of Mariy El':'Mari El Republic',\n",
    "                               'The City of Moscow':'Moscow',\n",
    "                               '     of which Nenets autonomous area':'Nenets Autonomous Okrug',\n",
    "                               'Nizhny novgorod Oblast':'Nizhny Novgorod Oblast', \n",
    "                               'Republic of North Ossetia–Alania':'Republic of North Ossetia-Alania',\n",
    "                               'Perm territory':'Perm Krai', 'Primorsky territory':'Primorsky Krai',\n",
    "                               'Republic of Sakha (Yakutia)':'Sakha (Yakutia) Republic',\n",
    "                               'Stavropol territory':'Stavropol Krai', 'Republic of Tyva':'Tuva Republic',\n",
    "                               '           Tyumen Oblast (without Khanty-Mansi autonomous area - Yugra and Yamalo-Nenets autonomous area)':'Tyumen Oblast',\n",
    "                               '           Yamalo-Nenets autonomous\\narea':'Yamalo-Nenets Autonomous Okrug',\n",
    "                               'Jewish autonomous Oblast':'Jewish Autonomous Oblast',\n",
    "                               'Zabaykalsky territory':'Zabaykalsky Krai'}})\n",
    "\n",
    "df_salary_filled.columns = 'A' + df_salary_filled.columns\n",
    "\n",
    "df_salary_filled = df_salary_filled.rename(columns={'Aregion':'region'})\n",
    "\n",
    "df_salary_long = pd.wide_to_long(df_salary_filled, [\"A\"], i=\"region\", j=\"year\")\n",
    "df_salary_long = df_salary_long.reset_index()\n",
    "df_salary_long = df_salary_long.drop(index=df_salary_long[(df_salary_long.year == 2017)].index, axis=0)\n",
    "df_salary_long = df_salary_long.rename(columns={'A':'Salary'})\n",
    "df_with_grp_salary = df_with_grp.merge(df_salary_long, how='inner', on=['region','year'])\n",
    "df_with_grp_salary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot correlation\n",
    "plot_correlation(df_with_grp_salary.drop(['year','cluster','muslim','GRP'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_report(df_with_grp_salary.drop(['year','cluster','muslim','GRP'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "inflation_link = 'https://api.worldbank.org/v2/en/indicator/FP.CPI.TOTL.ZG?downloadformat=excel'\n",
    "df_inf = pd.read_excel(inflation_link, skiprows=3, index_col=0)\n",
    "\n",
    "# Choose row ‘’Russian Federation” and columns from 2000 to 2016\n",
    "inf_rate = df_inf.loc['Russian Federation', '2000':'2016']\n",
    "pd.DataFrame(inf_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create “Expected_salary” column\n",
    "df_with_grp_salary['Expected_salary'] = 0\n",
    "\n",
    "# Fill it. In 2000, “Expected salary” is a real salary\n",
    "# Every next year “Expected salary” is a previous year “Expected salary” multiplied by (1 + 0.01 of “Inflation rate”)\n",
    "for i in range(17):\n",
    "    if i == 0:\n",
    "        df_with_grp_salary.loc[df_with_grp_salary.year == int(inf_rate.index[i]), 'Expected_salary'] = \\\n",
    "        df_with_grp_salary['Salary']\n",
    "    else:\n",
    "        df_with_grp_salary.loc[df_with_grp_salary.year == int(inf_rate.index[i]), 'Expected_salary'] = \\\n",
    "        np.array(df_with_grp_salary[df_with_grp_salary.year == int(inf_rate.index[i-1])]['Expected_salary'] * (1 + 0.01*inf_rate[i-1]))\n",
    "\n",
    "#Create “Difference in salaries” feature\n",
    "df_with_grp_salary['Salary_diff'] = df_with_grp_salary['Salary'] - df_with_grp_salary['Expected_salary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot correlation\n",
    "plot_correlation(df_with_grp_salary.drop(['year','cluster','muslim',\n",
    "                                          'GRP','Salary','Expected_salary'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw plots\n",
    "df_with_grp_salary_reg = df_with_grp_salary.set_index(['region','year']).sort_index()\n",
    "old_i = 'region'\n",
    "\n",
    "fig, ax = plt.subplots(3, 3, figsize=(20,15))\n",
    "fig.delaxes(ax[2,2])\n",
    "\n",
    "\n",
    "for i, row in df_with_grp_salary_reg.iterrows():\n",
    "\n",
    "    if i[0] != old_i:\n",
    "        df_temp = df_with_grp_salary_reg.loc[i[0]]\n",
    "\n",
    "        ax[0,0].plot(df_temp.index, df_temp.wine, label='wine',color='r', alpha=0.15)\n",
    "        ax[0,1].plot(df_temp.index, df_temp.beer, label='beer',color='b', alpha=0.15)\n",
    "        ax[0,2].plot(df_temp.index, df_temp.champagne, label='champagne',color='g', alpha=0.15)\n",
    "        ax[1,0].plot(df_temp.index, df_temp.vodka, label='vodka',color='m', alpha=0.15)\n",
    "        ax[1,1].plot(df_temp.index, df_temp.brandy, label='brandy',color='y', alpha=0.15)\n",
    "        ax[1,2].plot(df_temp.index, norm(df_temp.GRP), label='GRP',color='teal', alpha=0.15)\n",
    "        ax[2,0].plot(df_temp.index, df_temp.Salary, label='salary',color='peru', alpha=0.15)\n",
    "        ax[2,1].plot(df_temp.index, df_temp.Salary_diff, label='salary_diff',color='navy', alpha=0.15)\n",
    "\n",
    "        old_i = i[0]\n",
    "\n",
    "ax[0,0].title.set_text('Wine consumption per year (all regions)')\n",
    "ax[0,1].title.set_text('Beer consumption per year (all regions)')\n",
    "ax[0,2].title.set_text('Champagne consumption per year (all regions)')\n",
    "ax[1,0].title.set_text('Vodka consumption per year (all regions)')\n",
    "ax[1,1].title.set_text('Brandy consumption per year (all regions)')\n",
    "ax[1,2].title.set_text('GRP (all regions)')\n",
    "ax[2,0].title.set_text('Salary (all regions)')\n",
    "ax[2,1].title.set_text('Salary difference (all regions)')\n",
    "\n",
    "ax[0,0].set_xticks(df_year.index[2:])\n",
    "ax[0,1].set_xticks(df_year.index[2:])\n",
    "ax[0,2].set_xticks(df_year.index[2:])\n",
    "ax[1,0].set_xticks(df_year.index[2:])\n",
    "ax[1,1].set_xticks(df_year.index[2:])\n",
    "ax[1,2].set_xticks(df_year.index[2:])\n",
    "ax[2,0].set_xticks(df_year.index[2:])\n",
    "ax[2,1].set_xticks(df_year.index[2:])\n",
    "\n",
    "ax[0,0].set_xticklabels(df_year.index[2:], rotation=90)\n",
    "ax[0,1].set_xticklabels(df_year.index[2:], rotation=90)\n",
    "ax[0,2].set_xticklabels(df_year.index[2:], rotation=90)\n",
    "ax[1,0].set_xticklabels(df_year.index[2:], rotation=90)\n",
    "ax[1,1].set_xticklabels(df_year.index[2:], rotation=90)\n",
    "ax[1,2].set_xticklabels(df_year.index[2:], rotation=90)\n",
    "ax[2,0].set_xticklabels(df_year.index[2:], rotation=90)\n",
    "ax[2,1].set_xticklabels(df_year.index[2:], rotation=90)\n",
    "\n",
    "ax[0,0].set_ylabel('Litres per capita')\n",
    "ax[0,1].set_ylabel('Litres per capita')\n",
    "ax[0,2].set_ylabel('Litres per capita')\n",
    "ax[1,0].set_ylabel('Litres per capita')\n",
    "ax[1,1].set_ylabel('Litres per capita')\n",
    "ax[1,2].set_ylabel('Normed GRP')\n",
    "ax[2,0].set_ylabel('Salary')\n",
    "ax[2,1].set_ylabel('Salary difference')\n",
    "\n",
    "plt.tight_layout()\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add dummy restriction features\n",
    "df_with_grp_salary_restr = df_with_grp_salary\n",
    "df_with_grp_salary_restr['Adv_ban'] = 0\n",
    "df_with_grp_salary_restr['Hidden_adv_ban'] = 0\n",
    "df_with_grp_salary_restr['Minimum_vodka_price'] = 0\n",
    "df_with_grp_salary_restr['Night_sales_ban'] = 0\n",
    "df_with_grp_salary_restr['Beer_adv_ban'] = 0\n",
    "\n",
    "df_with_grp_salary_restr.loc[df_with_grp_salary_restr.year >= 2004, 'Adv_ban'] = 1\n",
    "df_with_grp_salary_restr.loc[df_with_grp_salary_restr.year >= 2006, 'Hidden_adv_ban'] = 1\n",
    "df_with_grp_salary_restr.loc[df_with_grp_salary_restr.year >= 2010, 'Minimum_vodka_price'] = 1\n",
    "df_with_grp_salary_restr.loc[df_with_grp_salary_restr.year >= 2011, 'Night_sales_ban'] = 1\n",
    "df_with_grp_salary_restr.loc[df_with_grp_salary_restr.year >= 2013, 'Beer_adv_ban'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Common plot with restictions\n",
    "plt.figure(figsize=[15,6])\n",
    "plt.xticks(df_year.index)\n",
    "\n",
    "for col in df_year.columns:\n",
    "    sns.lineplot(data=df_year, x=df_year.index, y=norm(df_year[col]), label=str(col))\n",
    "\n",
    "leg1= plt.legend(labels=['wine','beer','vodka','champagne','brandy'], loc='upper left')\n",
    "plt.title('Alcohol consumption per year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Alcohol consumption (normed)')\n",
    "plt.axvline(x=2004, linestyle='--',linewidth=1.3, color='darkred', label='TV advertising ban (people, animals)')\n",
    "plt.axvline(x=2006, linestyle='--',linewidth=1.3, color='olive', label='Hidden advertising ban')\n",
    "plt.axvline(x=2010, linestyle='--',linewidth=1.3, color='dimgray', label='Minimum vodka price')\n",
    "plt.axvline(x=2011, linestyle='--',linewidth=1.3, color='teal', label='Night sales ban')\n",
    "plt.axvline(x=2013, linestyle='--',linewidth=1.3, color='darkgreen', label='Beer advertising ban')\n",
    "leg2= plt.legend(labels=['TV advertising ban (people, animals)','Hidden advertising ban','Minimum vodka price',\n",
    "                        'Night sales ban','Beer advertising ban'],\n",
    "                bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "plt.gca().add_artist(leg1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for every drink with restrictions\n",
    "fig, ax = plt.subplots(2, 3, figsize=(20,15))\n",
    "fig.delaxes(ax[1,2])\n",
    "\n",
    "ax[0,0].plot(df_year.index, df_year.wine, label='wine',color='r')\n",
    "ax[0,1].plot(df_year.index, df_year.beer, label='beer',color='b')\n",
    "ax[0,2].plot(df_year.index, df_year.champagne, label='champagne',color='g')\n",
    "ax[1,0].plot(df_year.index, df_year.vodka, label='vodka',color='m')\n",
    "ax[1,1].plot(df_year.index, df_year.brandy, label='brandy',color='y')\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        if i == 1 and j == 2:\n",
    "            break\n",
    "        ax[i,j].axvline(x=2004, linestyle='--',linewidth=1.3, color='darkred', label='TV advertising ban (people, animals)')\n",
    "        ax[i,j].axvline(x=2006, linestyle='--',linewidth=1.3, color='olive', label='Hidden advertising ban')\n",
    "        ax[i,j].axvline(x=2010, linestyle='--',linewidth=1.3, color='dimgray', label='Minimum vodka price')\n",
    "        ax[i,j].axvline(x=2011, linestyle='--',linewidth=1.3, color='teal', label='Night sales ban')\n",
    "        ax[i,j].axvline(x=2013, linestyle='--',linewidth=1.3, color='darkgreen', label='Beer advertising ban')\n",
    "\n",
    "ax[0,0].title.set_text('Wine consumption per year')\n",
    "ax[0,1].title.set_text('Beer consumption per year')\n",
    "ax[0,2].title.set_text('Champagne consumption per year')\n",
    "ax[1,0].title.set_text('Vodka consumption per year')\n",
    "ax[1,1].title.set_text('Brandy consumption per year')\n",
    "\n",
    "ax[0,0].set_xticks(df_year.index)\n",
    "ax[0,1].set_xticks(df_year.index)\n",
    "ax[0,2].set_xticks(df_year.index)\n",
    "ax[1,0].set_xticks(df_year.index)\n",
    "ax[1,1].set_xticks(df_year.index)\n",
    "\n",
    "ax[0,0].set_xticklabels(df_year.index, rotation=90)\n",
    "ax[0,1].set_xticklabels(df_year.index, rotation=90)\n",
    "ax[0,2].set_xticklabels(df_year.index, rotation=90)\n",
    "ax[1,0].set_xticklabels(df_year.index, rotation=90)\n",
    "ax[1,1].set_xticklabels(df_year.index, rotation=90)\n",
    "\n",
    "ax[0,0].set_ylabel('Litres per capita')\n",
    "ax[0,1].set_ylabel('Litres per capita')\n",
    "ax[0,2].set_ylabel('Litres per capita')\n",
    "ax[1,0].set_ylabel('Litres per capita')\n",
    "ax[1,1].set_ylabel('Litres per capita')\n",
    "\n",
    "ax[1,0].legend(labels=['TV advertising ban (people, animals)','Hidden advertising ban','Minimum vodka price',\n",
    "                        'Night sales ban','Beer advertising ban'], loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot correlation\n",
    "plot_correlation(df_with_grp_salary_restr.drop(['year','Expected_salary','cluster', 'muslim',\n",
    "                                               'GRP','Salary','Salary_diff'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add technical features “Saved money”\n",
    "df_with_grp_salary_restr['Saved_money_2%'] = df_with_grp_salary_restr['Salary'] - (df_with_grp_salary_restr['Salary'] * 0.02 * \\\n",
    "                        ((1 - df_with_grp_salary_restr['Adv_ban']) + (1-df_with_grp_salary_restr['Hidden_adv_ban']) + \\\n",
    "                        (1-df_with_grp_salary_restr['Minimum_vodka_price']) + (1-df_with_grp_salary_restr['Beer_adv_ban']) + \\\n",
    "                        (1-df_with_grp_salary_restr['Night_sales_ban'])))\n",
    "df_with_grp_salary_restr['Saved_money_5%'] = df_with_grp_salary_restr['Salary'] - (df_with_grp_salary_restr['Salary'] * 0.05 * \\\n",
    "                        ((1 - df_with_grp_salary_restr['Adv_ban']) + (1-df_with_grp_salary_restr['Hidden_adv_ban']) + \\\n",
    "                        (1-df_with_grp_salary_restr['Minimum_vodka_price']) + (1-df_with_grp_salary_restr['Beer_adv_ban']) + \\\n",
    "                        (1-df_with_grp_salary_restr['Night_sales_ban'])))\n",
    "\n",
    "# Plot correlation (add “Salary” as a parent feature)\n",
    "plot_correlation(df_with_grp_salary_restr.drop(['year','Expected_salary','cluster', 'muslim', 'Salary_diff',\n",
    "                                               'GRP','Adv_ban', 'Hidden_adv_ban', 'Minimum_vodka_price',\n",
    "                                                'Beer_adv_ban','Night_sales_ban'], axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data by year\n",
    "df_with_grp_salary_restr_by_year = df_with_grp_salary_restr.groupby(\"year\")[['wine', 'beer', 'vodka', 'champagne', \n",
    "             'brandy','Salary_diff','GRP', 'Salary', 'Adv_ban',\n",
    "                                                                             'Hidden_adv_ban', 'Minimum_vodka_price',\n",
    "                                                                             'Beer_adv_ban', 'Night_sales_ban',\n",
    "                                                                             'Saved_money_2%', 'Saved_money_5%']].sum()\n",
    "\n",
    "# Create mean values for new features\n",
    "for col in ['GRP', 'Salary', 'Adv_ban', 'Salary_diff', 'Hidden_adv_ban', 'Minimum_vodka_price',\n",
    "            'Beer_adv_ban', 'Night_sales_ban', 'Saved_money_2%', 'Saved_money_5%']:\n",
    "        df_with_grp_salary_restr_by_year[col] = df_with_grp_salary_restr_by_year[col]/83\n",
    "\n",
    "plot_correlation(df_with_grp_salary_restr_by_year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict vodka consumption using basic dataset\n",
    "reg = GradientBoostingRegressor()\n",
    "\n",
    "# First step: drop all new features, second step: create dummy-features for each region\n",
    "X = df_with_grp_salary_restr.drop(['year', 'vodka','cluster', 'muslim', 'GRP', 'Salary', 'Expected_salary', 'Salary_diff',\n",
    "       'Adv_ban', 'Hidden_adv_ban', 'Minimum_vodka_price', 'Beer_adv_ban',\n",
    "       'Night_sales_ban', 'Saved_money_2%', 'Saved_money_5%'], axis=1)\n",
    "X = pd.get_dummies(X, columns=['region'], dtype='int64')\n",
    "y = df_with_grp_salary_restr.vodka\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=26)\n",
    "\n",
    "reg.fit(X_train,y_train)\n",
    "print(f'R2 score of train part (basic dataset): {reg.score(X_train,y_train):.4f}')\n",
    "print(f'R2 score of test part (basic dataset): {reg.score(X_test,y_test):.4f}')\n",
    "\n",
    "# Predict vodka consumption using modified dataset without dummies \n",
    "\n",
    "# First step: drop restriction dummy features and Saved_money, second step: create dummy-features for each region\n",
    "X = df_with_grp_salary_restr.drop(['year', 'vodka','cluster', 'muslim', 'GRP', 'Salary', 'Expected_salary', 'Salary_diff'], axis=1)\n",
    "X = pd.get_dummies(X, columns=['region'], dtype='int64')\n",
    "y = df_with_grp_salary_restr.vodka\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=26)\n",
    "\n",
    "reg.fit(X_train,y_train)\n",
    "print(f'R2 score of train part (dataset without dummies): {reg.score(X_train,y_train):.4f}')\n",
    "print(f'R2 score of test part (dataset without dummies): {reg.score(X_test,y_test):.4f}')\n",
    "\n",
    "# Predict vodka consumption using modified dataset \n",
    "\n",
    "# First step: save all features, second step: create dummy-features for each region\n",
    "X = df_with_grp_salary_restr.drop(['year', 'vodka'], axis=1)\n",
    "X = pd.get_dummies(X, columns=['region'], dtype='int64')\n",
    "y = df_with_grp_salary_restr.vodka\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=26)\n",
    "\n",
    "reg.fit(X_train,y_train)\n",
    "print(f'R2 score of train part (full modified dataset): {reg.score(X_train,y_train):.4f}')\n",
    "print(f'R2 score of test part (full modified dataset): {reg.score(X_test,y_test):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict beer consumption using basic dataset\n",
    "reg = GradientBoostingRegressor()\n",
    "\n",
    "# First step: drop all new features, second step: create dummy-features for each region\n",
    "X = df_with_grp_salary_restr.drop(['year', 'beer','cluster', 'muslim', 'GRP', 'Salary', 'Expected_salary', 'Salary_diff',\n",
    "       'Adv_ban', 'Hidden_adv_ban', 'Minimum_vodka_price', 'Beer_adv_ban',\n",
    "       'Night_sales_ban', 'Saved_money_2%', 'Saved_money_5%'], axis=1)\n",
    "X = pd.get_dummies(X, columns=['region'], dtype='int64')\n",
    "y = df_with_grp_salary_restr.beer\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=26)\n",
    "\n",
    "reg.fit(X_train,y_train)\n",
    "print(f'R2 score of train part (basic dataset): {reg.score(X_train,y_train):.4f}')\n",
    "print(f'R2 score of test part (basic dataset): {reg.score(X_test,y_test):.4f}')\n",
    "\n",
    "# Predict beer consumption using modified dataset without dummies \n",
    "\n",
    "# First step: drop restriction dummy features and Saved_money, second step: create dummy-features for each region\n",
    "X = df_with_grp_salary_restr.drop(['year', 'beer', 'cluster', 'muslim', 'GRP', 'Salary', 'Expected_salary', 'Salary_diff'], axis=1)\n",
    "X = pd.get_dummies(X, columns=['region'], dtype='int64')\n",
    "y = df_with_grp_salary_restr.beer\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=26)\n",
    "\n",
    "reg.fit(X_train,y_train)\n",
    "print(f'R2 score of train part (dataset without dummies): {reg.score(X_train,y_train):.4f}')\n",
    "print(f'R2 score of test part (dataset without dummies): {reg.score(X_test,y_test):.4f}')\n",
    "\n",
    "# Predict beer consumption using modified dataset \n",
    "\n",
    "# First step: save all features, second step: create dummy-features for each region\n",
    "X = df_with_grp_salary_restr.drop(['year', 'beer'], axis=1)\n",
    "X = pd.get_dummies(X, columns=['region'], dtype='int64')\n",
    "y = df_with_grp_salary_restr.beer\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=26)\n",
    "\n",
    "reg.fit(X_train,y_train)\n",
    "print(f'R2 score of train part (full modified dataset): {reg.score(X_train,y_train):.4f}')\n",
    "print(f'R2 score of test part (full modified dataset): {reg.score(X_test,y_test):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict alcohol consumption using different sets of features\n",
    "reg = GradientBoostingRegressor()\n",
    "\n",
    "count=0\n",
    "fig, ax = plt.subplots(5,2, figsize=(10,50))\n",
    "\n",
    "for drink in ['wine', 'beer', 'vodka', 'champagne', 'brandy']:\n",
    "\n",
    "    df_r2_train = pd.DataFrame(columns=['r2_basic_features_train','r2_features_without_dummies_train','r2_all_features_train'])\n",
    "    df_r2_test = pd.DataFrame(columns=['r2_basic_features_test','r2_features_without_dummies_test','r2_all_features_test'])\n",
    "\n",
    "    for i in range(50):\n",
    "        \n",
    "        # Predict drink consumption using basic dataset\n",
    "\n",
    "        # First step: drop all new features, second step: create dummy-features for each region\n",
    "        X = df_with_grp_salary_restr.drop([drink, 'year', 'cluster', 'muslim', 'GRP', 'Salary', 'Expected_salary', 'Salary_diff',\n",
    "               'Adv_ban', 'Hidden_adv_ban', 'Minimum_vodka_price', 'Beer_adv_ban',\n",
    "               'Night_sales_ban', 'Saved_money_2%', 'Saved_money_5%'], axis=1)\n",
    "        X = pd.get_dummies(X, columns=['region'], dtype='int64')\n",
    "        y = df_with_grp_salary_restr[drink]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=i)\n",
    "\n",
    "        reg.fit(X_train,y_train)\n",
    "        df_r2_train.loc[i, 'r2_basic_features_train'] = reg.score(X_train,y_train)\n",
    "        df_r2_test.loc[i, 'r2_basic_features_test'] = reg.score(X_test,y_test)\n",
    "\n",
    "        # Predict drink consumption using modified dataset without dummies \n",
    "\n",
    "        # First step: drop restriction dummy features and Saved_money, second step: create dummy-features for each region\n",
    "        X = df_with_grp_salary_restr.drop([drink, 'year', 'cluster', 'muslim', 'GRP', 'Salary', 'Expected_salary', 'Salary_diff'], axis=1)\n",
    "        X = pd.get_dummies(X, columns=['region'], dtype='int64')\n",
    "        y = df_with_grp_salary_restr[drink]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=i)\n",
    "\n",
    "        reg.fit(X_train,y_train)\n",
    "        df_r2_train.loc[i, 'r2_features_without_dummies_train'] = reg.score(X_train,y_train)\n",
    "        df_r2_test.loc[i, 'r2_features_without_dummies_test'] = reg.score(X_test,y_test)\n",
    "\n",
    "        # Predict drink consumption using modified dataset \n",
    "\n",
    "        # First step: save all features, second step: create dummy-features for each region\n",
    "        X = df_with_grp_salary_restr.drop([drink, 'year'], axis=1)\n",
    "        X = pd.get_dummies(X, columns=['region'], dtype='int64')\n",
    "        y = df_with_grp_salary_restr[drink]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=i)\n",
    "\n",
    "        reg.fit(X_train,y_train)\n",
    "        df_r2_train.loc[i, 'r2_all_features_train'] = reg.score(X_train,y_train)\n",
    "        df_r2_test.loc[i, 'r2_all_features_test'] = reg.score(X_test,y_test)\n",
    "        \n",
    "    # Plot predictions\n",
    "                      \n",
    "    sns.boxplot(data=df_r2_train, ax=ax[count,0])\n",
    "    sns.boxplot(data=df_r2_test, ax=ax[count,1])\n",
    "    ax[count,0].set_xticklabels(df_r2_train.columns, rotation=30)\n",
    "    ax[count,1].set_xticklabels(df_r2_test.columns, rotation=30)\n",
    "    ax[count,0].title.set_text(f'R2 values of {drink} prediction (train)')\n",
    "    ax[count,1].title.set_text(f'R2 values of {drink} prediction (test)')\n",
    "    \n",
    "    df_cor = pd.DataFrame(columns=['Pearson_basic_and_no_dummies', 'Mann_Whitney_basic_and_no_dummies',\n",
    "                                  'Pearson_basic_and_all_features', 'Mann_Whitney_basic_and_all_features',\n",
    "                                  'Pearson_all_features_and_no_dummies', 'Mann_Whitney_all_features_and_no_dummies'],\n",
    "                          index=['train','test'])\n",
    "\n",
    "    df_cor.iloc[0,0] = pearsonr(df_r2_train.r2_basic_features_train, df_r2_train.r2_features_without_dummies_train)[1]\n",
    "    df_cor.iloc[0,1] = mannwhitneyu(df_r2_train.r2_basic_features_train, df_r2_train.r2_features_without_dummies_train)[1]\n",
    "    df_cor.iloc[0,2] = pearsonr(df_r2_train.r2_basic_features_train, df_r2_train.r2_all_features_train)[1]\n",
    "    df_cor.iloc[0,3] = mannwhitneyu(df_r2_train.r2_basic_features_train, df_r2_train.r2_all_features_train)[1]\n",
    "    df_cor.iloc[0,4] = pearsonr(df_r2_train.r2_features_without_dummies_train, df_r2_train.r2_all_features_train)[1]\n",
    "    df_cor.iloc[0,5] = mannwhitneyu(df_r2_train.r2_features_without_dummies_train, df_r2_train.r2_all_features_train)[1]\n",
    "\n",
    "    df_cor.iloc[1,0] = pearsonr(df_r2_test.r2_basic_features_test, df_r2_test.r2_features_without_dummies_test)[1]\n",
    "    df_cor.iloc[1,1] = mannwhitneyu(df_r2_test.r2_basic_features_test, df_r2_test.r2_features_without_dummies_test)[1]\n",
    "    df_cor.iloc[1,2] = pearsonr(df_r2_test.r2_basic_features_test, df_r2_test.r2_all_features_test)[1]\n",
    "    df_cor.iloc[1,3] = mannwhitneyu(df_r2_test.r2_basic_features_test, df_r2_test.r2_all_features_test)[1]\n",
    "    df_cor.iloc[1,4] = pearsonr(df_r2_test.r2_features_without_dummies_test, df_r2_test.r2_all_features_test)[1]\n",
    "    df_cor.iloc[1,5] = mannwhitneyu(df_r2_test.r2_features_without_dummies_test, df_r2_test.r2_all_features_test)[1]\n",
    "\n",
    "    # Check p-value\n",
    "    \n",
    "    for k in range(df_cor.shape[0]):\n",
    "        for l in range(df_cor.shape[1]):\n",
    "            if df_cor.iloc[k,l] > 0.05:\n",
    "                print(f'{drink} {df_cor.columns[l]} {df_cor.index[k]} p-val = {df_cor.iloc[k,l]}')\n",
    "        \n",
    "    count += 1\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dependent_variables = ['wine', 'beer', 'vodka', 'champagne', 'brandy']\n",
    "features = ['GRP', 'Salary', 'Salary_diff',\n",
    "       'Adv_ban', 'Hidden_adv_ban', 'Minimum_vodka_price', 'Night_sales_ban',\n",
    "       'Beer_adv_ban', 'Saved_money_2%', 'Saved_money_5%']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check null hypothesis: the new variables are completely uncorrelated with alcohol consumption\n",
    "\n",
    "for i in features:\n",
    "    for j in dependent_variables:\n",
    "\n",
    "        r_obs = pearsonr(df_with_grp_salary_restr[i], df_with_grp_salary_restr[j])\n",
    "        perm_replicates = np.empty(10000)\n",
    "\n",
    "        for repl_num in range(10000):\n",
    "            first_permuted = np.random.permutation(df_with_grp_salary_restr[i])\n",
    "            perm_replicates[repl_num] = abs(pearsonr(first_permuted, df_with_grp_salary_restr[j])[0])\n",
    "\n",
    "        p = np.sum(perm_replicates >= abs(r_obs[0]))/10000\n",
    "        \n",
    "        if (p > 0.05) or (r_obs[1] > 0.05): \n",
    "        \n",
    "            print(f'manual p-val {i} and {j} = {p}')\n",
    "            print(f'scipy p-val {i} and {j} = {r_obs[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot correlation\n",
    "plot_correlation(df_with_grp_salary_restr.drop(['year','cluster','muslim','Expected_salary'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check null hypothesis: the new variables are completely uncorrelated with alcohol consumption (grouped by year data)\n",
    "\n",
    "for i in features:\n",
    "    for j in dependent_variables:\n",
    "\n",
    "        r_obs = pearsonr(df_with_grp_salary_restr_by_year[i], df_with_grp_salary_restr_by_year[j])\n",
    "        perm_replicates = np.empty(10000)\n",
    "\n",
    "        for repl_num in range(10000):\n",
    "            first_permuted = np.random.permutation(df_with_grp_salary_restr_by_year[i])\n",
    "            perm_replicates[repl_num] = abs(pearsonr(first_permuted, df_with_grp_salary_restr_by_year[j])[0])\n",
    "\n",
    "        p = np.sum(perm_replicates >= abs(r_obs[0]))/10000\n",
    "        \n",
    "        if (p > 0.05) or (r_obs[1] > 0.05): \n",
    "        \n",
    "            print(f'manual p-val {i} and {j} = {p}')\n",
    "            print(f'scipy p-val {i} and {j} = {r_obs[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot correlation\n",
    "plot_correlation(df_with_grp_salary_restr_by_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with clusters and mean salaries\n",
    "df_clus_sal = df_with_grp_salary_restr.groupby('region')[['cluster','Salary']].mean()\n",
    "\n",
    "# Merge with Geopandas\n",
    "drw_russia_clus_sal = drw_russia.merge(df_clus_sal, how='left', left_on='NAME_1',\n",
    "                                        right_on=df_clus_sal.index)\n",
    "\n",
    "# Clean columns\n",
    "drw_russia_clus_sal = drw_russia_clus_sal.drop(['GID_0','NAME_0','GID_1','NL_NAME_1','GID_2','NAME_2','NL_NAME_2','GID_3',\n",
    "                           'NAME_3','VARNAME_3','NL_NAME_3','TYPE_3','ENGTYPE_3','CC_3','HASC_3'], axis=1)\n",
    "\n",
    "# Plot cluster map\n",
    "drw_russia_clus_sal.plot('cluster', figsize=(10, 6), legend=True, categorical=True, cmap='plasma')\n",
    "plt.xlim(0,200)\n",
    "plt.title('Results of KMeans clusterization')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot salaries\n",
    "drw_russia_clus_sal.plot('Salary', figsize=(10, 6), legend=True, categorical=False, cmap='magma')\n",
    "plt.xlim(0,200)\n",
    "plt.title('Mean salary by region (in roubles)')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of regions\n",
    "poisoned_regions = ['Penza Oblast','Kursk Oblast', 'Chuvash Republic','Kemerovo Oblast', \n",
    "'Republic of Buryatia', 'Astrakhan Oblast','Krasnoyarsk Krai', 'Republic of Khakassia', 'Ryazan Oblast',\n",
    "'Irkutsk Oblast', 'Udmurt Republic', 'Novosibirsk Oblast','Ulyanovsk Oblast']\n",
    "\n",
    "# Check the names\n",
    "set(poisoned_regions).intersection(set(df_clus_three.region))\n",
    "set(poisoned_regions).difference(set(df_clus_three.region))\n",
    "\n",
    "# Add to Geopandas dataframe\n",
    "df_clus_sal['Poisoned'] = 'low'\n",
    "df_clus_sal.loc[poisoned_regions, 'Poisoned'] = 'high'\n",
    "drw_russia_clus_sal = drw_russia.merge(df_clus_sal, how='left', left_on='NAME_1',\n",
    "                                        right_on=df_clus_sal.index)\n",
    "drw_russia_clus_sal = drw_russia_clus_sal.drop(['GID_0','NAME_0','GID_1','NL_NAME_1','GID_2','NAME_2','NL_NAME_2','GID_3',\n",
    "                           'NAME_3','VARNAME_3','NL_NAME_3','TYPE_3','ENGTYPE_3','CC_3','HASC_3'], axis=1)\n",
    "\n",
    "# Plot map of regions with high level of poison\n",
    "drw_russia_clus_sal.plot('Poisoned', figsize=(10, 6), legend=True, categorical=True, cmap='magma')\n",
    "plt.xlim(0,200)\n",
    "plt.title('Levels of acute poisoning')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create crosstab DataFrame\n",
    "pd.crosstab(df_clus_sal['cluster'], df_clus_sal['Poisoned'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_env",
   "language": "python",
   "name": "geo_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
